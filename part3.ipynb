{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c48830",
   "metadata": {},
   "source": [
    "## LELEC2870 - Machine Learning Project\n",
    "### Heart Failure Prediction in Smurf Society\n",
    "---\n",
    "\n",
    "# Part 3 - Integration of Image Data\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc12386",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f3b90",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5ca813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression as mutual_info\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "import random\n",
    "import scipy.io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from PIL import Image  # \"PIL\" stands for the \"pillow\" library.  \n",
    "# Pillow is a dependency of pytorch. Hence, if you installed pytorch correctly, you should not have anything else to install.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e129b51",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5baca52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   age                1000 non-null   int64  \n",
      " 1   blood pressure     1000 non-null   float64\n",
      " 2   calcium            1000 non-null   float64\n",
      " 3   cholesterol        1000 non-null   float64\n",
      " 4   hemoglobin         1000 non-null   float64\n",
      " 5   height             1000 non-null   float64\n",
      " 6   potassium          1000 non-null   float64\n",
      " 7   profession         1000 non-null   object \n",
      " 8   sarsaparilla       1000 non-null   object \n",
      " 9   smurfberry liquor  1000 non-null   object \n",
      " 10  smurfin donuts     1000 non-null   object \n",
      " 11  vitamin D          1000 non-null   float64\n",
      " 12  weight             1000 non-null   float64\n",
      " 13  img_filename       1000 non-null   object \n",
      "dtypes: float64(8), int64(1), object(5)\n",
      "memory usage: 109.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 1 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   heart_failure_risk  1000 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 7.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('data/data_labeled/X_train.csv')\n",
    "X_test = pd.read_csv('data/data_labeled/X_test.csv')\n",
    "\n",
    "# y CSV files don't have headers, so we need to specify header=None and provide column names\n",
    "y_train = pd.read_csv('data/data_labeled/y_train.csv', header=None, names=['heart_failure_risk'])\n",
    "y_test = pd.read_csv('data/data_labeled/y_test.csv', header=None, names=['heart_failure_risk'])\n",
    "\n",
    "# Extract image paths before dropping the column\n",
    "img_paths_train = [os.path.join('data/data_labeled/Img_train', name) for name in X_train['img_filename'].values]\n",
    "img_paths_test = [os.path.join('data/data_labeled/Img_test', name) for name in X_test['img_filename'].values]\n",
    "\n",
    "# Explore the data\n",
    "print(X_train.info())\n",
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a44d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   age                                       1000 non-null   int64  \n",
      " 1   blood pressure                            1000 non-null   float64\n",
      " 2   calcium                                   1000 non-null   float64\n",
      " 3   cholesterol                               1000 non-null   float64\n",
      " 4   hemoglobin                                1000 non-null   float64\n",
      " 5   height                                    1000 non-null   float64\n",
      " 6   potassium                                 1000 non-null   float64\n",
      " 7   sarsaparilla                              1000 non-null   object \n",
      " 8   smurfberry liquor                         1000 non-null   object \n",
      " 9   smurfin donuts                            1000 non-null   object \n",
      " 10  vitamin D                                 1000 non-null   float64\n",
      " 11  weight                                    1000 non-null   float64\n",
      " 12  profession_administration and governance  1000 non-null   bool   \n",
      " 13  profession_craftsmanship                  1000 non-null   bool   \n",
      " 14  profession_food production                1000 non-null   bool   \n",
      " 15  profession_manufacturing                  1000 non-null   bool   \n",
      " 16  profession_resource extraction            1000 non-null   bool   \n",
      " 17  profession_services                       1000 non-null   bool   \n",
      "dtypes: bool(6), float64(8), int64(1), object(3)\n",
      "memory usage: 99.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   age                                       500 non-null    int64  \n",
      " 1   blood pressure                            500 non-null    float64\n",
      " 2   calcium                                   500 non-null    float64\n",
      " 3   cholesterol                               500 non-null    float64\n",
      " 4   hemoglobin                                500 non-null    float64\n",
      " 5   height                                    500 non-null    float64\n",
      " 6   potassium                                 500 non-null    float64\n",
      " 7   sarsaparilla                              500 non-null    object \n",
      " 8   smurfberry liquor                         500 non-null    object \n",
      " 9   smurfin donuts                            500 non-null    object \n",
      " 10  vitamin D                                 500 non-null    float64\n",
      " 11  weight                                    500 non-null    float64\n",
      " 12  profession_administration and governance  500 non-null    bool   \n",
      " 13  profession_craftsmanship                  500 non-null    bool   \n",
      " 14  profession_food production                500 non-null    bool   \n",
      " 15  profession_manufacturing                  500 non-null    bool   \n",
      " 16  profession_resource extraction            500 non-null    bool   \n",
      " 17  profession_services                       500 non-null    bool   \n",
      "dtypes: bool(6), float64(8), int64(1), object(3)\n",
      "memory usage: 49.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# delete missing values in y_train\n",
    "y_train = y_train.dropna()\n",
    "\n",
    "# print length of y_train\n",
    "print(len(y_train))\n",
    "\n",
    "X_train = X_train.drop(columns=['img_filename'])\n",
    "X_test = X_test.drop(columns=['img_filename'])\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=['profession'])\n",
    "X_test = pd.get_dummies(X_test, columns=['profession'])\n",
    "\n",
    "print(X_train.info())\n",
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041cd2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   age                                       1000 non-null   int64  \n",
      " 1   blood pressure                            1000 non-null   float64\n",
      " 2   calcium                                   1000 non-null   float64\n",
      " 3   cholesterol                               1000 non-null   float64\n",
      " 4   hemoglobin                                1000 non-null   float64\n",
      " 5   height                                    1000 non-null   float64\n",
      " 6   potassium                                 1000 non-null   float64\n",
      " 7   sarsaparilla                              1000 non-null   int64  \n",
      " 8   smurfberry liquor                         1000 non-null   int64  \n",
      " 9   smurfin donuts                            1000 non-null   int64  \n",
      " 10  vitamin D                                 1000 non-null   float64\n",
      " 11  weight                                    1000 non-null   float64\n",
      " 12  profession_administration and governance  1000 non-null   bool   \n",
      " 13  profession_craftsmanship                  1000 non-null   bool   \n",
      " 14  profession_food production                1000 non-null   bool   \n",
      " 15  profession_manufacturing                  1000 non-null   bool   \n",
      " 16  profession_resource extraction            1000 non-null   bool   \n",
      " 17  profession_services                       1000 non-null   bool   \n",
      "dtypes: bool(6), float64(8), int64(4)\n",
      "memory usage: 99.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Strip whitespace from the three columns\n",
    "X_train['sarsaparilla'] = X_train['sarsaparilla'].str.strip()\n",
    "X_test['sarsaparilla'] = X_test['sarsaparilla'].str.strip()\n",
    "X_train['smurfberry liquor'] = X_train['smurfberry liquor'].str.strip()\n",
    "X_test['smurfberry liquor'] = X_test['smurfberry liquor'].str.strip()\n",
    "X_train['smurfin donuts'] = X_train['smurfin donuts'].str.strip()\n",
    "X_test['smurfin donuts'] = X_test['smurfin donuts'].str.strip()\n",
    "\n",
    "\n",
    "X_train['sarsaparilla'] = X_train['sarsaparilla'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "X_test['x'] = X_test['sarsaparilla'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "X_train['smurfberry liquor'] = X_train['smurfberry liquor'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "X_test['smurfberry liquor'] = X_test['smurfberry liquor'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "X_train['smurfin donuts'] = X_train['smurfin donuts'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "X_test['smurfin donuts'] = X_test['smurfin donuts'].map({'Very high': 4, 'High': 3, 'Moderate': 2, 'Low': 1, 'Very low': 0})\n",
    "\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb194bd",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b2d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize only numerical features (not ordinal or one-hot encoded)\n",
    "numerical_features = ['age', 'blood pressure', 'calcium', 'cholesterol', 'hemoglobin', \n",
    "                      'height', 'potassium', 'vitamin D', 'weight']\n",
    "\n",
    "# Create a copy to avoid modifying original data\n",
    "X_train_standardized = X_train.copy()\n",
    "X_test_standardized = X_test.copy()\n",
    "\n",
    "# Standardize only numerical features\n",
    "scX = StandardScaler()\n",
    "scX.fit(X_train[numerical_features])\n",
    "X_train_standardized[numerical_features] = scX.transform(X_train[numerical_features])\n",
    "X_test_standardized[numerical_features] = scX.transform(X_test[numerical_features])\n",
    "\n",
    "# Update X_train and X_test\n",
    "X_train = X_train_standardized\n",
    "X_test = X_test_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5a7f2",
   "metadata": {},
   "source": [
    "## 2. Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb83a7b",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a924366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Root Mean Square Error\n",
    "def compute_rmse(predict, target):\n",
    "\n",
    "    len_predict = len(predict)\n",
    "    len_target = len(target)\n",
    "    \n",
    "    if len_predict != len_target:\n",
    "        raise ValueError(\"predict and target must have the same length\")\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((predict - target) ** 2))\n",
    "    \n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a1c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepeatedKFold: 10 total folds (10 splits x 5 repeats)\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Setup\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "print(f\"RepeatedKFold: {rkf.get_n_splits()} total folds (10 splits x 5 repeats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d2e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for multimodal data (images + tabular)\n",
    "# Optimized: Accepts pre-loaded images to avoid loading them multiple times\n",
    "class HeartDataset(Dataset):\n",
    "    def __init__(self, X_tabular, y, preloaded_images=None, image_paths=None, transform=None):\n",
    "        # Ensure tabular data is a float32 NumPy array (no object dtype)\n",
    "        if hasattr(X_tabular, 'to_numpy'):\n",
    "            X_np = X_tabular.to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            X_np = np.asarray(X_tabular, dtype=np.float32)\n",
    "        \n",
    "        if hasattr(y, 'to_numpy'):\n",
    "            y_np = y.to_numpy(dtype=np.float32).reshape(-1)\n",
    "        else:\n",
    "            y_np = np.asarray(y, dtype=np.float32).reshape(-1)\n",
    "\n",
    "        self.X_tabular = torch.from_numpy(X_np)\n",
    "        self.y = torch.from_numpy(y_np)\n",
    "        \n",
    "        # Use pre-loaded images if provided, otherwise load them\n",
    "        if preloaded_images is not None:\n",
    "            self.images = preloaded_images\n",
    "        elif image_paths is not None:\n",
    "            # Fallback: load images if preloaded_images not provided\n",
    "            self.images = []\n",
    "            for path in image_paths:\n",
    "                img = Image.open(path).convert('L')\n",
    "                if transform:\n",
    "                    img = transform(img)\n",
    "                self.images.append(img)\n",
    "        else:\n",
    "            raise ValueError(\"Either preloaded_images or image_paths must be provided\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return pre-loaded image (no file I/O here!)\n",
    "        return self.images[idx], self.X_tabular[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Multimodal CNN: processes image through convolutions, then fuses with tabular data\n",
    "class MultiModalCNN(nn.Module):\n",
    "    def __init__(self, n_tabular_features, n_neurons=64):\n",
    "        super(MultiModalCNN, self).__init__()\n",
    "        \n",
    "        # Image branch (input: 1 x 48 x 48)\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)  # -> 48x48\n",
    "        self.pool1 = nn.MaxPool2d(2)                                       # -> 24x24\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1)   # -> 24x24\n",
    "        self.pool2 = nn.MaxPool2d(2)                                       # -> 12x12\n",
    "        \n",
    "        self.flat_size = 8 * 12 * 12  # = 1152\n",
    "        \n",
    "        # Fusion layers\n",
    "        self.fc1 = nn.Linear(self.flat_size + n_tabular_features, n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, image, tabular):\n",
    "        # Image path\n",
    "        x = self.relu(self.conv1(image))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, self.flat_size)\n",
    "        \n",
    "        # Fuse with tabular data\n",
    "        x = torch.cat((x, tabular), dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0111496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Device: mps\n",
      "\n",
      "============================================================\n",
      "PRE-LOADING ALL IMAGES (done once before CV)\n",
      "============================================================\n",
      "Pre-loading 1000 images into memory...\n",
      "  Loaded 100/1000 images...\n",
      "  Loaded 200/1000 images...\n",
      "  Loaded 300/1000 images...\n",
      "  Loaded 400/1000 images...\n",
      "  Loaded 500/1000 images...\n",
      "  Loaded 600/1000 images...\n",
      "  Loaded 700/1000 images...\n",
      "  Loaded 800/1000 images...\n",
      "  Loaded 900/1000 images...\n",
      "  Loaded 1000/1000 images...\n",
      "Finished loading all 1000 images.\n",
      "\n",
      "Starting Cross-Validation:\n",
      "  Total samples: 1000\n",
      "  Total folds: 10\n",
      "  Hyperparameters: n_neurons=16, batch_size=32, lr=0.002, epochs=35\n",
      "\n",
      "\n",
      "============================================================\n",
      "Fold 1/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.005674\n",
      "    Epoch 2/35 - Avg Loss: 0.003064\n",
      "    Epoch 3/35 - Avg Loss: 0.002336\n",
      "    Epoch 4/35 - Avg Loss: 0.001953\n",
      "    Epoch 5/35 - Avg Loss: 0.001300\n",
      "    Epoch 6/35 - Avg Loss: 0.001041\n",
      "    Epoch 7/35 - Avg Loss: 0.000760\n",
      "    Epoch 8/35 - Avg Loss: 0.000654\n",
      "    Epoch 9/35 - Avg Loss: 0.000591\n",
      "    Epoch 10/35 - Avg Loss: 0.000479\n",
      "    Epoch 11/35 - Avg Loss: 0.000426\n",
      "    Epoch 12/35 - Avg Loss: 0.000389\n",
      "    Epoch 13/35 - Avg Loss: 0.000435\n",
      "    Epoch 14/35 - Avg Loss: 0.000263\n",
      "    Epoch 15/35 - Avg Loss: 0.000249\n",
      "    Epoch 16/35 - Avg Loss: 0.000273\n",
      "    Epoch 17/35 - Avg Loss: 0.000218\n",
      "    Epoch 18/35 - Avg Loss: 0.000191\n",
      "    Epoch 19/35 - Avg Loss: 0.000156\n",
      "    Epoch 20/35 - Avg Loss: 0.000202\n",
      "    Epoch 21/35 - Avg Loss: 0.000190\n",
      "    Epoch 22/35 - Avg Loss: 0.000149\n",
      "    Epoch 23/35 - Avg Loss: 0.000129\n",
      "    Epoch 24/35 - Avg Loss: 0.000121\n",
      "    Epoch 25/35 - Avg Loss: 0.000117\n",
      "    Epoch 26/35 - Avg Loss: 0.000093\n",
      "    Epoch 27/35 - Avg Loss: 0.000090\n",
      "    Epoch 28/35 - Avg Loss: 0.000074\n",
      "    Epoch 29/35 - Avg Loss: 0.000113\n",
      "    Epoch 30/35 - Avg Loss: 0.000092\n",
      "    Epoch 31/35 - Avg Loss: 0.000087\n",
      "    Epoch 32/35 - Avg Loss: 0.000076\n",
      "    Epoch 33/35 - Avg Loss: 0.000065\n",
      "    Epoch 34/35 - Avg Loss: 0.000055\n",
      "    Epoch 35/35 - Avg Loss: 0.000048\n",
      "  Evaluating on validation set...\n",
      "  Fold 1 RMSE: 0.0337\n",
      "\n",
      "============================================================\n",
      "Fold 2/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.006011\n",
      "    Epoch 2/35 - Avg Loss: 0.003181\n",
      "    Epoch 3/35 - Avg Loss: 0.002273\n",
      "    Epoch 4/35 - Avg Loss: 0.001796\n",
      "    Epoch 5/35 - Avg Loss: 0.001239\n",
      "    Epoch 6/35 - Avg Loss: 0.000936\n",
      "    Epoch 7/35 - Avg Loss: 0.000724\n",
      "    Epoch 8/35 - Avg Loss: 0.000606\n",
      "    Epoch 9/35 - Avg Loss: 0.000481\n",
      "    Epoch 10/35 - Avg Loss: 0.000465\n",
      "    Epoch 11/35 - Avg Loss: 0.000398\n",
      "    Epoch 12/35 - Avg Loss: 0.000374\n",
      "    Epoch 13/35 - Avg Loss: 0.000306\n",
      "    Epoch 14/35 - Avg Loss: 0.000269\n",
      "    Epoch 15/35 - Avg Loss: 0.000208\n",
      "    Epoch 16/35 - Avg Loss: 0.000205\n",
      "    Epoch 17/35 - Avg Loss: 0.000184\n",
      "    Epoch 18/35 - Avg Loss: 0.000154\n",
      "    Epoch 19/35 - Avg Loss: 0.000153\n",
      "    Epoch 20/35 - Avg Loss: 0.000127\n",
      "    Epoch 21/35 - Avg Loss: 0.000115\n",
      "    Epoch 22/35 - Avg Loss: 0.000129\n",
      "    Epoch 23/35 - Avg Loss: 0.000109\n",
      "    Epoch 24/35 - Avg Loss: 0.000091\n",
      "    Epoch 25/35 - Avg Loss: 0.000112\n",
      "    Epoch 26/35 - Avg Loss: 0.000099\n",
      "    Epoch 27/35 - Avg Loss: 0.000095\n",
      "    Epoch 28/35 - Avg Loss: 0.000074\n",
      "    Epoch 29/35 - Avg Loss: 0.000066\n",
      "    Epoch 30/35 - Avg Loss: 0.000071\n",
      "    Epoch 31/35 - Avg Loss: 0.000053\n",
      "    Epoch 32/35 - Avg Loss: 0.000052\n",
      "    Epoch 33/35 - Avg Loss: 0.000049\n",
      "    Epoch 34/35 - Avg Loss: 0.000045\n",
      "    Epoch 35/35 - Avg Loss: 0.000046\n",
      "  Evaluating on validation set...\n",
      "  Fold 2 RMSE: 0.0404\n",
      "\n",
      "============================================================\n",
      "Fold 3/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.009872\n",
      "    Epoch 2/35 - Avg Loss: 0.003494\n",
      "    Epoch 3/35 - Avg Loss: 0.002950\n",
      "    Epoch 4/35 - Avg Loss: 0.002776\n",
      "    Epoch 5/35 - Avg Loss: 0.002463\n",
      "    Epoch 6/35 - Avg Loss: 0.002245\n",
      "    Epoch 7/35 - Avg Loss: 0.002066\n",
      "    Epoch 8/35 - Avg Loss: 0.002154\n",
      "    Epoch 9/35 - Avg Loss: 0.001908\n",
      "    Epoch 10/35 - Avg Loss: 0.001816\n",
      "    Epoch 11/35 - Avg Loss: 0.001635\n",
      "    Epoch 12/35 - Avg Loss: 0.001540\n",
      "    Epoch 13/35 - Avg Loss: 0.001330\n",
      "    Epoch 14/35 - Avg Loss: 0.001159\n",
      "    Epoch 15/35 - Avg Loss: 0.001091\n",
      "    Epoch 16/35 - Avg Loss: 0.000956\n",
      "    Epoch 17/35 - Avg Loss: 0.000965\n",
      "    Epoch 18/35 - Avg Loss: 0.000888\n",
      "    Epoch 19/35 - Avg Loss: 0.000752\n",
      "    Epoch 20/35 - Avg Loss: 0.000681\n",
      "    Epoch 21/35 - Avg Loss: 0.000676\n",
      "    Epoch 22/35 - Avg Loss: 0.000561\n",
      "    Epoch 23/35 - Avg Loss: 0.000553\n",
      "    Epoch 24/35 - Avg Loss: 0.000506\n",
      "    Epoch 25/35 - Avg Loss: 0.000479\n",
      "    Epoch 26/35 - Avg Loss: 0.000448\n",
      "    Epoch 27/35 - Avg Loss: 0.000399\n",
      "    Epoch 28/35 - Avg Loss: 0.000365\n",
      "    Epoch 29/35 - Avg Loss: 0.000328\n",
      "    Epoch 30/35 - Avg Loss: 0.000332\n",
      "    Epoch 31/35 - Avg Loss: 0.000276\n",
      "    Epoch 32/35 - Avg Loss: 0.000291\n",
      "    Epoch 33/35 - Avg Loss: 0.000285\n",
      "    Epoch 34/35 - Avg Loss: 0.000274\n",
      "    Epoch 35/35 - Avg Loss: 0.000243\n",
      "  Evaluating on validation set...\n",
      "  Fold 3 RMSE: 0.0422\n",
      "\n",
      "============================================================\n",
      "Fold 4/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.007389\n",
      "    Epoch 2/35 - Avg Loss: 0.003230\n",
      "    Epoch 3/35 - Avg Loss: 0.002847\n",
      "    Epoch 4/35 - Avg Loss: 0.002741\n",
      "    Epoch 5/35 - Avg Loss: 0.002563\n",
      "    Epoch 6/35 - Avg Loss: 0.002489\n",
      "    Epoch 7/35 - Avg Loss: 0.002239\n",
      "    Epoch 8/35 - Avg Loss: 0.002269\n",
      "    Epoch 9/35 - Avg Loss: 0.002000\n",
      "    Epoch 10/35 - Avg Loss: 0.001888\n",
      "    Epoch 11/35 - Avg Loss: 0.001758\n",
      "    Epoch 12/35 - Avg Loss: 0.001627\n",
      "    Epoch 13/35 - Avg Loss: 0.001509\n",
      "    Epoch 14/35 - Avg Loss: 0.001439\n",
      "    Epoch 15/35 - Avg Loss: 0.001331\n",
      "    Epoch 16/35 - Avg Loss: 0.001208\n",
      "    Epoch 17/35 - Avg Loss: 0.001163\n",
      "    Epoch 18/35 - Avg Loss: 0.001259\n",
      "    Epoch 19/35 - Avg Loss: 0.001094\n",
      "    Epoch 20/35 - Avg Loss: 0.001091\n",
      "    Epoch 21/35 - Avg Loss: 0.000947\n",
      "    Epoch 22/35 - Avg Loss: 0.000992\n",
      "    Epoch 23/35 - Avg Loss: 0.000892\n",
      "    Epoch 24/35 - Avg Loss: 0.000809\n",
      "    Epoch 25/35 - Avg Loss: 0.000812\n",
      "    Epoch 26/35 - Avg Loss: 0.000729\n",
      "    Epoch 27/35 - Avg Loss: 0.000710\n",
      "    Epoch 28/35 - Avg Loss: 0.000655\n",
      "    Epoch 29/35 - Avg Loss: 0.000717\n",
      "    Epoch 30/35 - Avg Loss: 0.000586\n",
      "    Epoch 31/35 - Avg Loss: 0.000599\n",
      "    Epoch 32/35 - Avg Loss: 0.000598\n",
      "    Epoch 33/35 - Avg Loss: 0.000591\n",
      "    Epoch 34/35 - Avg Loss: 0.000564\n",
      "    Epoch 35/35 - Avg Loss: 0.000554\n",
      "  Evaluating on validation set...\n",
      "  Fold 4 RMSE: 0.0522\n",
      "\n",
      "============================================================\n",
      "Fold 5/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.018363\n",
      "    Epoch 2/35 - Avg Loss: 0.005763\n",
      "    Epoch 3/35 - Avg Loss: 0.004263\n",
      "    Epoch 4/35 - Avg Loss: 0.003004\n",
      "    Epoch 5/35 - Avg Loss: 0.002586\n",
      "    Epoch 6/35 - Avg Loss: 0.002381\n",
      "    Epoch 7/35 - Avg Loss: 0.002296\n",
      "    Epoch 8/35 - Avg Loss: 0.002224\n",
      "    Epoch 9/35 - Avg Loss: 0.002131\n",
      "    Epoch 10/35 - Avg Loss: 0.002123\n",
      "    Epoch 11/35 - Avg Loss: 0.001981\n",
      "    Epoch 12/35 - Avg Loss: 0.001933\n",
      "    Epoch 13/35 - Avg Loss: 0.001900\n",
      "    Epoch 14/35 - Avg Loss: 0.001988\n",
      "    Epoch 15/35 - Avg Loss: 0.001865\n",
      "    Epoch 16/35 - Avg Loss: 0.001855\n",
      "    Epoch 17/35 - Avg Loss: 0.001690\n",
      "    Epoch 18/35 - Avg Loss: 0.001656\n",
      "    Epoch 19/35 - Avg Loss: 0.001736\n",
      "    Epoch 20/35 - Avg Loss: 0.001671\n",
      "    Epoch 21/35 - Avg Loss: 0.001525\n",
      "    Epoch 22/35 - Avg Loss: 0.001483\n",
      "    Epoch 23/35 - Avg Loss: 0.001420\n",
      "    Epoch 24/35 - Avg Loss: 0.001368\n",
      "    Epoch 25/35 - Avg Loss: 0.001316\n",
      "    Epoch 26/35 - Avg Loss: 0.001288\n",
      "    Epoch 27/35 - Avg Loss: 0.001236\n",
      "    Epoch 28/35 - Avg Loss: 0.001229\n",
      "    Epoch 29/35 - Avg Loss: 0.001126\n",
      "    Epoch 30/35 - Avg Loss: 0.001079\n",
      "    Epoch 31/35 - Avg Loss: 0.001081\n",
      "    Epoch 32/35 - Avg Loss: 0.001036\n",
      "    Epoch 33/35 - Avg Loss: 0.001083\n",
      "    Epoch 34/35 - Avg Loss: 0.001037\n",
      "    Epoch 35/35 - Avg Loss: 0.000960\n",
      "  Evaluating on validation set...\n",
      "  Fold 5 RMSE: 0.0484\n",
      "\n",
      "============================================================\n",
      "Fold 6/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.006359\n",
      "    Epoch 2/35 - Avg Loss: 0.003326\n",
      "    Epoch 3/35 - Avg Loss: 0.002888\n",
      "    Epoch 4/35 - Avg Loss: 0.002504\n",
      "    Epoch 5/35 - Avg Loss: 0.002218\n",
      "    Epoch 6/35 - Avg Loss: 0.002004\n",
      "    Epoch 7/35 - Avg Loss: 0.001903\n",
      "    Epoch 8/35 - Avg Loss: 0.001885\n",
      "    Epoch 9/35 - Avg Loss: 0.001655\n",
      "    Epoch 10/35 - Avg Loss: 0.001639\n",
      "    Epoch 11/35 - Avg Loss: 0.001397\n",
      "    Epoch 12/35 - Avg Loss: 0.001359\n",
      "    Epoch 13/35 - Avg Loss: 0.001261\n",
      "    Epoch 14/35 - Avg Loss: 0.001202\n",
      "    Epoch 15/35 - Avg Loss: 0.001154\n",
      "    Epoch 16/35 - Avg Loss: 0.001067\n",
      "    Epoch 17/35 - Avg Loss: 0.001023\n",
      "    Epoch 18/35 - Avg Loss: 0.001127\n",
      "    Epoch 19/35 - Avg Loss: 0.000986\n",
      "    Epoch 20/35 - Avg Loss: 0.001051\n",
      "    Epoch 21/35 - Avg Loss: 0.000942\n",
      "    Epoch 22/35 - Avg Loss: 0.000835\n",
      "    Epoch 23/35 - Avg Loss: 0.000775\n",
      "    Epoch 24/35 - Avg Loss: 0.000699\n",
      "    Epoch 25/35 - Avg Loss: 0.000697\n",
      "    Epoch 26/35 - Avg Loss: 0.000663\n",
      "    Epoch 27/35 - Avg Loss: 0.000619\n",
      "    Epoch 28/35 - Avg Loss: 0.000663\n",
      "    Epoch 29/35 - Avg Loss: 0.000602\n",
      "    Epoch 30/35 - Avg Loss: 0.000560\n",
      "    Epoch 31/35 - Avg Loss: 0.000558\n",
      "    Epoch 32/35 - Avg Loss: 0.000516\n",
      "    Epoch 33/35 - Avg Loss: 0.000490\n",
      "    Epoch 34/35 - Avg Loss: 0.000538\n",
      "    Epoch 35/35 - Avg Loss: 0.000487\n",
      "  Evaluating on validation set...\n",
      "  Fold 6 RMSE: 0.0447\n",
      "\n",
      "============================================================\n",
      "Fold 7/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.009394\n",
      "    Epoch 2/35 - Avg Loss: 0.003465\n",
      "    Epoch 3/35 - Avg Loss: 0.002986\n",
      "    Epoch 4/35 - Avg Loss: 0.002510\n",
      "    Epoch 5/35 - Avg Loss: 0.002248\n",
      "    Epoch 6/35 - Avg Loss: 0.002072\n",
      "    Epoch 7/35 - Avg Loss: 0.001714\n",
      "    Epoch 8/35 - Avg Loss: 0.001482\n",
      "    Epoch 9/35 - Avg Loss: 0.001304\n",
      "    Epoch 10/35 - Avg Loss: 0.001355\n",
      "    Epoch 11/35 - Avg Loss: 0.000955\n",
      "    Epoch 12/35 - Avg Loss: 0.000755\n",
      "    Epoch 13/35 - Avg Loss: 0.000673\n",
      "    Epoch 14/35 - Avg Loss: 0.000621\n",
      "    Epoch 15/35 - Avg Loss: 0.000545\n",
      "    Epoch 16/35 - Avg Loss: 0.000484\n",
      "    Epoch 17/35 - Avg Loss: 0.000573\n",
      "    Epoch 18/35 - Avg Loss: 0.000445\n",
      "    Epoch 19/35 - Avg Loss: 0.000375\n",
      "    Epoch 20/35 - Avg Loss: 0.000304\n",
      "    Epoch 21/35 - Avg Loss: 0.000259\n",
      "    Epoch 22/35 - Avg Loss: 0.000313\n",
      "    Epoch 23/35 - Avg Loss: 0.000212\n",
      "    Epoch 24/35 - Avg Loss: 0.000196\n",
      "    Epoch 25/35 - Avg Loss: 0.000170\n",
      "    Epoch 26/35 - Avg Loss: 0.000230\n",
      "    Epoch 27/35 - Avg Loss: 0.000253\n",
      "    Epoch 28/35 - Avg Loss: 0.000247\n",
      "    Epoch 29/35 - Avg Loss: 0.000173\n",
      "    Epoch 30/35 - Avg Loss: 0.000187\n",
      "    Epoch 31/35 - Avg Loss: 0.000116\n",
      "    Epoch 32/35 - Avg Loss: 0.000135\n",
      "    Epoch 33/35 - Avg Loss: 0.000136\n",
      "    Epoch 34/35 - Avg Loss: 0.000103\n",
      "    Epoch 35/35 - Avg Loss: 0.000082\n",
      "  Evaluating on validation set...\n",
      "  Fold 7 RMSE: 0.0328\n",
      "\n",
      "============================================================\n",
      "Fold 8/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.006972\n",
      "    Epoch 2/35 - Avg Loss: 0.003001\n",
      "    Epoch 3/35 - Avg Loss: 0.002529\n",
      "    Epoch 4/35 - Avg Loss: 0.002326\n",
      "    Epoch 5/35 - Avg Loss: 0.002200\n",
      "    Epoch 6/35 - Avg Loss: 0.001928\n",
      "    Epoch 7/35 - Avg Loss: 0.001610\n",
      "    Epoch 8/35 - Avg Loss: 0.001316\n",
      "    Epoch 9/35 - Avg Loss: 0.001079\n",
      "    Epoch 10/35 - Avg Loss: 0.000976\n",
      "    Epoch 11/35 - Avg Loss: 0.000924\n",
      "    Epoch 12/35 - Avg Loss: 0.000725\n",
      "    Epoch 13/35 - Avg Loss: 0.000680\n",
      "    Epoch 14/35 - Avg Loss: 0.000573\n",
      "    Epoch 15/35 - Avg Loss: 0.000536\n",
      "    Epoch 16/35 - Avg Loss: 0.000519\n",
      "    Epoch 17/35 - Avg Loss: 0.000399\n",
      "    Epoch 18/35 - Avg Loss: 0.000335\n",
      "    Epoch 19/35 - Avg Loss: 0.000314\n",
      "    Epoch 20/35 - Avg Loss: 0.000266\n",
      "    Epoch 21/35 - Avg Loss: 0.000266\n",
      "    Epoch 22/35 - Avg Loss: 0.000232\n",
      "    Epoch 23/35 - Avg Loss: 0.000219\n",
      "    Epoch 24/35 - Avg Loss: 0.000207\n",
      "    Epoch 25/35 - Avg Loss: 0.000164\n",
      "    Epoch 26/35 - Avg Loss: 0.000140\n",
      "    Epoch 27/35 - Avg Loss: 0.000118\n",
      "    Epoch 28/35 - Avg Loss: 0.000116\n",
      "    Epoch 29/35 - Avg Loss: 0.000106\n",
      "    Epoch 30/35 - Avg Loss: 0.000121\n",
      "    Epoch 31/35 - Avg Loss: 0.000101\n",
      "    Epoch 32/35 - Avg Loss: 0.000085\n",
      "    Epoch 33/35 - Avg Loss: 0.000069\n",
      "    Epoch 34/35 - Avg Loss: 0.000062\n",
      "    Epoch 35/35 - Avg Loss: 0.000063\n",
      "  Evaluating on validation set...\n",
      "  Fold 8 RMSE: 0.0325\n",
      "\n",
      "============================================================\n",
      "Fold 9/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.012759\n",
      "    Epoch 2/35 - Avg Loss: 0.003411\n",
      "    Epoch 3/35 - Avg Loss: 0.002437\n",
      "    Epoch 4/35 - Avg Loss: 0.002037\n",
      "    Epoch 5/35 - Avg Loss: 0.001663\n",
      "    Epoch 6/35 - Avg Loss: 0.001427\n",
      "    Epoch 7/35 - Avg Loss: 0.001232\n",
      "    Epoch 8/35 - Avg Loss: 0.001071\n",
      "    Epoch 9/35 - Avg Loss: 0.000949\n",
      "    Epoch 10/35 - Avg Loss: 0.000831\n",
      "    Epoch 11/35 - Avg Loss: 0.000731\n",
      "    Epoch 12/35 - Avg Loss: 0.000676\n",
      "    Epoch 13/35 - Avg Loss: 0.000582\n",
      "    Epoch 14/35 - Avg Loss: 0.000582\n",
      "    Epoch 15/35 - Avg Loss: 0.000526\n",
      "    Epoch 16/35 - Avg Loss: 0.000460\n",
      "    Epoch 17/35 - Avg Loss: 0.000406\n",
      "    Epoch 18/35 - Avg Loss: 0.000391\n",
      "    Epoch 19/35 - Avg Loss: 0.000344\n",
      "    Epoch 20/35 - Avg Loss: 0.000346\n",
      "    Epoch 21/35 - Avg Loss: 0.000305\n",
      "    Epoch 22/35 - Avg Loss: 0.000279\n",
      "    Epoch 23/35 - Avg Loss: 0.000247\n",
      "    Epoch 24/35 - Avg Loss: 0.000235\n",
      "    Epoch 25/35 - Avg Loss: 0.000207\n",
      "    Epoch 26/35 - Avg Loss: 0.000205\n",
      "    Epoch 27/35 - Avg Loss: 0.000190\n",
      "    Epoch 28/35 - Avg Loss: 0.000176\n",
      "    Epoch 29/35 - Avg Loss: 0.000174\n",
      "    Epoch 30/35 - Avg Loss: 0.000161\n",
      "    Epoch 31/35 - Avg Loss: 0.000146\n",
      "    Epoch 32/35 - Avg Loss: 0.000132\n",
      "    Epoch 33/35 - Avg Loss: 0.000149\n",
      "    Epoch 34/35 - Avg Loss: 0.000130\n",
      "    Epoch 35/35 - Avg Loss: 0.000111\n",
      "  Evaluating on validation set...\n",
      "  Fold 9 RMSE: 0.0369\n",
      "\n",
      "============================================================\n",
      "Fold 10/10\n",
      "  Train samples: 800, Val samples: 200\n",
      "  Creating datasets...\n",
      "  Data loaders created\n",
      "  Training model...\n",
      "    Epoch 1/35 - Avg Loss: 0.004490\n",
      "    Epoch 2/35 - Avg Loss: 0.002653\n",
      "    Epoch 3/35 - Avg Loss: 0.002208\n",
      "    Epoch 4/35 - Avg Loss: 0.001551\n",
      "    Epoch 5/35 - Avg Loss: 0.001196\n",
      "    Epoch 6/35 - Avg Loss: 0.000940\n",
      "    Epoch 7/35 - Avg Loss: 0.000744\n",
      "    Epoch 8/35 - Avg Loss: 0.000713\n",
      "    Epoch 9/35 - Avg Loss: 0.000705\n",
      "    Epoch 10/35 - Avg Loss: 0.000490\n",
      "    Epoch 11/35 - Avg Loss: 0.000427\n",
      "    Epoch 12/35 - Avg Loss: 0.000376\n",
      "    Epoch 13/35 - Avg Loss: 0.000287\n",
      "    Epoch 14/35 - Avg Loss: 0.000257\n",
      "    Epoch 15/35 - Avg Loss: 0.000238\n",
      "    Epoch 16/35 - Avg Loss: 0.000192\n",
      "    Epoch 17/35 - Avg Loss: 0.000158\n",
      "    Epoch 18/35 - Avg Loss: 0.000154\n",
      "    Epoch 19/35 - Avg Loss: 0.000135\n",
      "    Epoch 20/35 - Avg Loss: 0.000118\n",
      "    Epoch 21/35 - Avg Loss: 0.000098\n",
      "    Epoch 22/35 - Avg Loss: 0.000083\n",
      "    Epoch 23/35 - Avg Loss: 0.000076\n",
      "    Epoch 24/35 - Avg Loss: 0.000080\n",
      "    Epoch 25/35 - Avg Loss: 0.000074\n",
      "    Epoch 26/35 - Avg Loss: 0.000067\n",
      "    Epoch 27/35 - Avg Loss: 0.000054\n",
      "    Epoch 28/35 - Avg Loss: 0.000055\n",
      "    Epoch 29/35 - Avg Loss: 0.000049\n",
      "    Epoch 30/35 - Avg Loss: 0.000047\n",
      "    Epoch 31/35 - Avg Loss: 0.000044\n",
      "    Epoch 32/35 - Avg Loss: 0.000037\n",
      "    Epoch 33/35 - Avg Loss: 0.000038\n",
      "    Epoch 34/35 - Avg Loss: 0.000049\n",
      "    Epoch 35/35 - Avg Loss: 0.000058\n",
      "  Evaluating on validation set...\n",
      "  Fold 10 RMSE: 0.0330\n",
      "\n",
      "Average RMSE: 0.0397 (+/- 0.0067)\n"
     ]
    }
   ],
   "source": [
    "# Training functions for K-Fold Cross-Validation\n",
    "\n",
    "# Set device: MPS (Apple Silicon) > CUDA (NVIDIA) > CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs, device):\n",
    "    \"\"\"Train the model for specified epochs.\"\"\"\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (imgs, tabs, labels) in enumerate(train_loader):\n",
    "            imgs, tabs, labels = imgs.to(device), tabs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs, tabs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        print(f\"    Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.6f}\")\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"Evaluate model and return predictions and targets.\"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, tabs, labels in val_loader:\n",
    "            imgs, tabs, labels = imgs.to(device), tabs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(imgs, tabs).squeeze()\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            targets.append(labels.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(preds), np.concatenate(targets)\n",
    "\n",
    "def preload_images(image_paths, transform):\n",
    "    \"\"\"Pre-load all images into memory once. Returns list of transformed tensors.\"\"\"\n",
    "    print(f\"Pre-loading {len(image_paths)} images into memory...\")\n",
    "    images = []\n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = Image.open(path).convert('L')  # Grayscale\n",
    "        if transform:\n",
    "            img = transform(img)\n",
    "        images.append(img)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Loaded {i + 1}/{len(image_paths)} images...\")\n",
    "    print(f\"Finished loading all {len(image_paths)} images.\\n\")\n",
    "    return images\n",
    "\n",
    "def run_cross_validation(X_train, y_train, img_paths_train, cv_splitter, \n",
    "                         model_class, n_tabular_features, \n",
    "                         n_neurons=16, batch_size=32, lr=0.001, epochs=10):\n",
    "    \"\"\"Run cross-validation and return list of RMSEs for each fold.\"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    # Pre-load ALL images ONCE before CV loop (saves massive time!)\n",
    "    print(\"=\"*60)\n",
    "    print(\"PRE-LOADING ALL IMAGES (done once before CV)\")\n",
    "    print(\"=\"*60)\n",
    "    all_preloaded_images = preload_images(img_paths_train, transform)\n",
    "    \n",
    "    fold_rmses = []\n",
    "    n_folds = cv_splitter.get_n_splits()\n",
    "    \n",
    "    print(f\"Starting Cross-Validation:\")\n",
    "    print(f\"  Total samples: {len(X_train)}\")\n",
    "    print(f\"  Total folds: {n_folds}\")\n",
    "    print(f\"  Hyperparameters: n_neurons={n_neurons}, batch_size={batch_size}, lr={lr}, epochs={epochs}\\n\")\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_train)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold_idx+1}/{n_folds}\")\n",
    "        print(f\"  Train samples: {len(train_idx)}, Val samples: {len(val_idx)}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_tr = X_train.iloc[train_idx]\n",
    "        X_val = X_train.iloc[val_idx]\n",
    "        y_tr = y_train.iloc[train_idx]\n",
    "        y_val = y_train.iloc[val_idx]\n",
    "        \n",
    "        # Get pre-loaded images for this fold (just slice the pre-loaded list)\n",
    "        img_tr = [all_preloaded_images[i] for i in train_idx]\n",
    "        img_val = [all_preloaded_images[i] for i in val_idx]\n",
    "        \n",
    "        # Create datasets using pre-loaded images (no file I/O!)\n",
    "        print(f\"  Creating datasets...\")\n",
    "        train_dataset = HeartDataset(X_tr, y_tr, preloaded_images=img_tr)\n",
    "        val_dataset = HeartDataset(X_val, y_val, preloaded_images=img_val)\n",
    "        \n",
    "        # Create data loaders (num_workers=0 to avoid multiprocessing issues in notebooks)\n",
    "        num_workers = 0  # Set to 0 for Jupyter notebooks (avoids pickling errors)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        \n",
    "        print(f\"  Data loaders created\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = model_class(n_tabular_features=n_tabular_features, n_neurons=n_neurons)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Train\n",
    "        print(f\"  Training model...\")\n",
    "        train_model(model, train_loader, criterion, optimizer, epochs, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        print(f\"  Evaluating on validation set...\")\n",
    "        preds, targets = evaluate_model(model, val_loader, device)\n",
    "        rmse = compute_rmse(preds, targets)\n",
    "        fold_rmses.append(rmse)\n",
    "        \n",
    "        print(f\"  Fold {fold_idx+1} RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return fold_rmses\n",
    "\n",
    "# Run cross-validation\n",
    "N_NEURONS = 16\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.002\n",
    "EPOCHS = 35\n",
    "\n",
    "fold_rmses = run_cross_validation(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    img_paths_train=img_paths_train,\n",
    "    cv_splitter=rkf,\n",
    "    model_class=MultiModalCNN,\n",
    "    n_tabular_features=X_train.shape[1],\n",
    "    n_neurons=N_NEURONS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"\\nAverage RMSE: {np.mean(fold_rmses):.4f} (+/- {np.std(fold_rmses):.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc38a86",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### CNN (trained) + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bfc7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loaded 1000 images.\n",
      "\n",
      "============================================================\n",
      "CNN + PCA + Random Forest Cross-Validation\n",
      "============================================================\n",
      "  Folds: 10\n",
      "  CNN: epochs=20, lr=0.002, n_neurons=4\n",
      "  PCA: 1152 CNN features → 20 components\n",
      "  RF: n_estimators=300, max_depth=10\n",
      "  Final features: 20 (CNN/PCA) + 18 (tabular) = 38\n",
      "============================================================\n",
      "\n",
      "--- Fold 1/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.006930\n",
      "    Epoch 2/20 - Loss: 0.003763\n",
      "    Epoch 3/20 - Loss: 0.003371\n",
      "    Epoch 4/20 - Loss: 0.003188\n",
      "    Epoch 5/20 - Loss: 0.002930\n",
      "    Epoch 6/20 - Loss: 0.002925\n",
      "    Epoch 7/20 - Loss: 0.002904\n",
      "    Epoch 8/20 - Loss: 0.002795\n",
      "    Epoch 9/20 - Loss: 0.002467\n",
      "    Epoch 10/20 - Loss: 0.002592\n",
      "    Epoch 11/20 - Loss: 0.002271\n",
      "    Epoch 12/20 - Loss: 0.002150\n",
      "    Epoch 13/20 - Loss: 0.002069\n",
      "    Epoch 14/20 - Loss: 0.002084\n",
      "    Epoch 15/20 - Loss: 0.002034\n",
      "    Epoch 16/20 - Loss: 0.001976\n",
      "    Epoch 17/20 - Loss: 0.001906\n",
      "    Epoch 18/20 - Loss: 0.001823\n",
      "    Epoch 19/20 - Loss: 0.001905\n",
      "    Epoch 20/20 - Loss: 0.001996\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 61.3%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 1 RMSE: 0.0409\n",
      "\n",
      "--- Fold 2/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.017039\n",
      "    Epoch 2/20 - Loss: 0.005302\n",
      "    Epoch 3/20 - Loss: 0.004100\n",
      "    Epoch 4/20 - Loss: 0.003449\n",
      "    Epoch 5/20 - Loss: 0.003288\n",
      "    Epoch 6/20 - Loss: 0.003199\n",
      "    Epoch 7/20 - Loss: 0.003172\n",
      "    Epoch 8/20 - Loss: 0.003094\n",
      "    Epoch 9/20 - Loss: 0.003012\n",
      "    Epoch 10/20 - Loss: 0.003103\n",
      "    Epoch 11/20 - Loss: 0.003100\n",
      "    Epoch 12/20 - Loss: 0.002857\n",
      "    Epoch 13/20 - Loss: 0.002918\n",
      "    Epoch 14/20 - Loss: 0.002904\n",
      "    Epoch 15/20 - Loss: 0.002785\n",
      "    Epoch 16/20 - Loss: 0.002827\n",
      "    Epoch 17/20 - Loss: 0.002701\n",
      "    Epoch 18/20 - Loss: 0.002794\n",
      "    Epoch 19/20 - Loss: 0.002631\n",
      "    Epoch 20/20 - Loss: 0.002592\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 57.9%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 2 RMSE: 0.0455\n",
      "\n",
      "--- Fold 3/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.006922\n",
      "    Epoch 2/20 - Loss: 0.003567\n",
      "    Epoch 3/20 - Loss: 0.002795\n",
      "    Epoch 4/20 - Loss: 0.002453\n",
      "    Epoch 5/20 - Loss: 0.002329\n",
      "    Epoch 6/20 - Loss: 0.002077\n",
      "    Epoch 7/20 - Loss: 0.001839\n",
      "    Epoch 8/20 - Loss: 0.001647\n",
      "    Epoch 9/20 - Loss: 0.001375\n",
      "    Epoch 10/20 - Loss: 0.001201\n",
      "    Epoch 11/20 - Loss: 0.001053\n",
      "    Epoch 12/20 - Loss: 0.000952\n",
      "    Epoch 13/20 - Loss: 0.000873\n",
      "    Epoch 14/20 - Loss: 0.000780\n",
      "    Epoch 15/20 - Loss: 0.000751\n",
      "    Epoch 16/20 - Loss: 0.000647\n",
      "    Epoch 17/20 - Loss: 0.000582\n",
      "    Epoch 18/20 - Loss: 0.000524\n",
      "    Epoch 19/20 - Loss: 0.000486\n",
      "    Epoch 20/20 - Loss: 0.000468\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 66.9%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 3 RMSE: 0.0404\n",
      "\n",
      "--- Fold 4/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.017626\n",
      "    Epoch 2/20 - Loss: 0.003882\n",
      "    Epoch 3/20 - Loss: 0.003109\n",
      "    Epoch 4/20 - Loss: 0.002890\n",
      "    Epoch 5/20 - Loss: 0.002836\n",
      "    Epoch 6/20 - Loss: 0.002691\n",
      "    Epoch 7/20 - Loss: 0.002798\n",
      "    Epoch 8/20 - Loss: 0.002641\n",
      "    Epoch 9/20 - Loss: 0.002826\n",
      "    Epoch 10/20 - Loss: 0.002824\n",
      "    Epoch 11/20 - Loss: 0.002419\n",
      "    Epoch 12/20 - Loss: 0.002301\n",
      "    Epoch 13/20 - Loss: 0.002286\n",
      "    Epoch 14/20 - Loss: 0.002243\n",
      "    Epoch 15/20 - Loss: 0.002207\n",
      "    Epoch 16/20 - Loss: 0.002108\n",
      "    Epoch 17/20 - Loss: 0.002105\n",
      "    Epoch 18/20 - Loss: 0.002076\n",
      "    Epoch 19/20 - Loss: 0.002106\n",
      "    Epoch 20/20 - Loss: 0.001983\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 61.8%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 4 RMSE: 0.0451\n",
      "\n",
      "--- Fold 5/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.008380\n",
      "    Epoch 2/20 - Loss: 0.003529\n",
      "    Epoch 3/20 - Loss: 0.003157\n",
      "    Epoch 4/20 - Loss: 0.002879\n",
      "    Epoch 5/20 - Loss: 0.002767\n",
      "    Epoch 6/20 - Loss: 0.002497\n",
      "    Epoch 7/20 - Loss: 0.002375\n",
      "    Epoch 8/20 - Loss: 0.002351\n",
      "    Epoch 9/20 - Loss: 0.002280\n",
      "    Epoch 10/20 - Loss: 0.002199\n",
      "    Epoch 11/20 - Loss: 0.002071\n",
      "    Epoch 12/20 - Loss: 0.002013\n",
      "    Epoch 13/20 - Loss: 0.002058\n",
      "    Epoch 14/20 - Loss: 0.001912\n",
      "    Epoch 15/20 - Loss: 0.001956\n",
      "    Epoch 16/20 - Loss: 0.001878\n",
      "    Epoch 17/20 - Loss: 0.001868\n",
      "    Epoch 18/20 - Loss: 0.001812\n",
      "    Epoch 19/20 - Loss: 0.001696\n",
      "    Epoch 20/20 - Loss: 0.001614\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 62.8%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 5 RMSE: 0.0469\n",
      "\n",
      "--- Fold 6/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.013439\n",
      "    Epoch 2/20 - Loss: 0.004510\n",
      "    Epoch 3/20 - Loss: 0.003612\n",
      "    Epoch 4/20 - Loss: 0.003237\n",
      "    Epoch 5/20 - Loss: 0.002941\n",
      "    Epoch 6/20 - Loss: 0.002943\n",
      "    Epoch 7/20 - Loss: 0.002808\n",
      "    Epoch 8/20 - Loss: 0.002711\n",
      "    Epoch 9/20 - Loss: 0.002587\n",
      "    Epoch 10/20 - Loss: 0.002527\n",
      "    Epoch 11/20 - Loss: 0.002293\n",
      "    Epoch 12/20 - Loss: 0.002295\n",
      "    Epoch 13/20 - Loss: 0.002264\n",
      "    Epoch 14/20 - Loss: 0.002064\n",
      "    Epoch 15/20 - Loss: 0.002039\n",
      "    Epoch 16/20 - Loss: 0.001892\n",
      "    Epoch 17/20 - Loss: 0.001885\n",
      "    Epoch 18/20 - Loss: 0.001844\n",
      "    Epoch 19/20 - Loss: 0.001918\n",
      "    Epoch 20/20 - Loss: 0.002023\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 59.8%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 6 RMSE: 0.0441\n",
      "\n",
      "--- Fold 7/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.006435\n",
      "    Epoch 2/20 - Loss: 0.003431\n",
      "    Epoch 3/20 - Loss: 0.002877\n",
      "    Epoch 4/20 - Loss: 0.002580\n",
      "    Epoch 5/20 - Loss: 0.002276\n",
      "    Epoch 6/20 - Loss: 0.002011\n",
      "    Epoch 7/20 - Loss: 0.001967\n",
      "    Epoch 8/20 - Loss: 0.001733\n",
      "    Epoch 9/20 - Loss: 0.001718\n",
      "    Epoch 10/20 - Loss: 0.001577\n",
      "    Epoch 11/20 - Loss: 0.001565\n",
      "    Epoch 12/20 - Loss: 0.001432\n",
      "    Epoch 13/20 - Loss: 0.001379\n",
      "    Epoch 14/20 - Loss: 0.001402\n",
      "    Epoch 15/20 - Loss: 0.001421\n",
      "    Epoch 16/20 - Loss: 0.001400\n",
      "    Epoch 17/20 - Loss: 0.001173\n",
      "    Epoch 18/20 - Loss: 0.001244\n",
      "    Epoch 19/20 - Loss: 0.001122\n",
      "    Epoch 20/20 - Loss: 0.001026\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 56.7%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 7 RMSE: 0.0395\n",
      "\n",
      "--- Fold 8/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.016391\n",
      "    Epoch 2/20 - Loss: 0.004458\n",
      "    Epoch 3/20 - Loss: 0.002872\n",
      "    Epoch 4/20 - Loss: 0.002542\n",
      "    Epoch 5/20 - Loss: 0.002387\n",
      "    Epoch 6/20 - Loss: 0.002232\n",
      "    Epoch 7/20 - Loss: 0.002094\n",
      "    Epoch 8/20 - Loss: 0.002005\n",
      "    Epoch 9/20 - Loss: 0.001861\n",
      "    Epoch 10/20 - Loss: 0.001773\n",
      "    Epoch 11/20 - Loss: 0.001666\n",
      "    Epoch 12/20 - Loss: 0.001565\n",
      "    Epoch 13/20 - Loss: 0.001459\n",
      "    Epoch 14/20 - Loss: 0.001436\n",
      "    Epoch 15/20 - Loss: 0.001263\n",
      "    Epoch 16/20 - Loss: 0.001207\n",
      "    Epoch 17/20 - Loss: 0.001106\n",
      "    Epoch 18/20 - Loss: 0.001007\n",
      "    Epoch 19/20 - Loss: 0.000906\n",
      "    Epoch 20/20 - Loss: 0.000887\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 69.4%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 8 RMSE: 0.0442\n",
      "\n",
      "--- Fold 9/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.007225\n",
      "    Epoch 2/20 - Loss: 0.005936\n",
      "    Epoch 3/20 - Loss: 0.005947\n",
      "    Epoch 4/20 - Loss: 0.005938\n",
      "    Epoch 5/20 - Loss: 0.005944\n",
      "    Epoch 6/20 - Loss: 0.005942\n",
      "    Epoch 7/20 - Loss: 0.005938\n",
      "    Epoch 8/20 - Loss: 0.005968\n",
      "    Epoch 9/20 - Loss: 0.005944\n",
      "    Epoch 10/20 - Loss: 0.005942\n",
      "    Epoch 11/20 - Loss: 0.005942\n",
      "    Epoch 12/20 - Loss: 0.005944\n",
      "    Epoch 13/20 - Loss: 0.005948\n",
      "    Epoch 14/20 - Loss: 0.005934\n",
      "    Epoch 15/20 - Loss: 0.005951\n",
      "    Epoch 16/20 - Loss: 0.005954\n",
      "    Epoch 17/20 - Loss: 0.005938\n",
      "    Epoch 18/20 - Loss: 0.005944\n",
      "    Epoch 19/20 - Loss: 0.005946\n",
      "    Epoch 20/20 - Loss: 0.005940\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 59.5%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 9 RMSE: 0.0502\n",
      "\n",
      "--- Fold 10/10 ---\n",
      "  Train: 800 samples, Val: 200 samples\n",
      "  [Step 1] Training CNN (20 epochs)...\n",
      "    Epoch 1/20 - Loss: 0.013780\n",
      "    Epoch 2/20 - Loss: 0.004192\n",
      "    Epoch 3/20 - Loss: 0.003437\n",
      "    Epoch 4/20 - Loss: 0.003153\n",
      "    Epoch 5/20 - Loss: 0.003079\n",
      "    Epoch 6/20 - Loss: 0.002957\n",
      "    Epoch 7/20 - Loss: 0.003049\n",
      "    Epoch 8/20 - Loss: 0.002913\n",
      "    Epoch 9/20 - Loss: 0.002802\n",
      "    Epoch 10/20 - Loss: 0.002617\n",
      "    Epoch 11/20 - Loss: 0.002703\n",
      "    Epoch 12/20 - Loss: 0.002363\n",
      "    Epoch 13/20 - Loss: 0.002383\n",
      "    Epoch 14/20 - Loss: 0.002283\n",
      "    Epoch 15/20 - Loss: 0.002334\n",
      "    Epoch 16/20 - Loss: 0.002355\n",
      "    Epoch 17/20 - Loss: 0.002037\n",
      "    Epoch 18/20 - Loss: 0.001973\n",
      "    Epoch 19/20 - Loss: 0.001788\n",
      "    Epoch 20/20 - Loss: 0.001689\n",
      "  [Step 2] Extracting CNN features...\n",
      "    Raw CNN features: 1152\n",
      "  [Step 3] Reducing with PCA (1152 → 20)...\n",
      "    Variance explained: 74.3%\n",
      "    Final features: 38 (20 CNN + 18 tabular)\n",
      "  [Step 4] Training Random Forest (300 trees)...\n",
      "  [Result] Fold 10 RMSE: 0.0436\n",
      "\n",
      "============================================================\n",
      "FINAL: Average RMSE = 0.0440 (+/- 0.0031)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract features from a TRAINED CNN (conv layers only, before FC)\n",
    "def extract_features_from_cnn(model, images, device):\n",
    "    \"\"\"Run images through trained conv layers, return flattened features.\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for img in images:\n",
    "            img = img.unsqueeze(0).to(device)\n",
    "            x = model.relu(model.conv1(img))\n",
    "            x = model.pool1(x)\n",
    "            x = model.relu(model.conv2(x))\n",
    "            x = model.pool2(x)\n",
    "            x = x.view(-1, model.flat_size)\n",
    "            features.append(x.cpu().numpy())\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "\n",
    "# Pre-load images once (reuse from above if already loaded)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "print(\"Loading images...\")\n",
    "all_images = [transform(Image.open(p).convert('L')) for p in img_paths_train]\n",
    "print(f\"Loaded {len(all_images)} images.\\n\")\n",
    "\n",
    "\n",
    "def run_cv_cnn_rf(X_train, y_train, all_images, cv_splitter,\n",
    "                  n_neurons=16, batch_size=32, lr=0.001, cnn_epochs=10,\n",
    "                  n_estimators=100, max_depth=10, pca_components=20):\n",
    "    \"\"\"\n",
    "    CV: Train CNN on each fold, extract features with trained conv layers, \n",
    "    reduce with PCA, then Random Forest.\n",
    "    \n",
    "    pca_components: number of PCA components to reduce CNN features to (default 20)\n",
    "                    This balances CNN features with tabular features (~18)\n",
    "    \"\"\"\n",
    "    fold_rmses = []\n",
    "    n_folds = cv_splitter.get_n_splits()\n",
    "    n_tabular = X_train.shape[1]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CNN + PCA + Random Forest Cross-Validation\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Folds: {n_folds}\")\n",
    "    print(f\"  CNN: epochs={cnn_epochs}, lr={lr}, n_neurons={n_neurons}\")\n",
    "    print(f\"  PCA: 1152 CNN features → {pca_components} components\")\n",
    "    print(f\"  RF: n_estimators={n_estimators}, max_depth={max_depth}\")\n",
    "    print(f\"  Final features: {pca_components} (CNN/PCA) + {n_tabular} (tabular) = {pca_components + n_tabular}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_train)):\n",
    "        print(f\"--- Fold {fold_idx+1}/{n_folds} ---\")\n",
    "        print(f\"  Train: {len(train_idx)} samples, Val: {len(val_idx)} samples\")\n",
    "        \n",
    "        # Split\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        img_tr = [all_images[i] for i in train_idx]\n",
    "        img_val = [all_images[i] for i in val_idx]\n",
    "        \n",
    "        # Step 1: Train CNN\n",
    "        print(f\"  [Step 1] Training CNN ({cnn_epochs} epochs)...\")\n",
    "        train_ds = HeartDataset(X_tr, y_tr, preloaded_images=img_tr)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        model = MultiModalCNN(n_tabular_features=X_train.shape[1], n_neurons=n_neurons).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(cnn_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for imgs, tabs, labels in train_loader:\n",
    "                imgs, tabs, labels = imgs.to(device), tabs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(imgs, tabs).squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"    Epoch {epoch+1}/{cnn_epochs} - Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        # Step 2: Extract features with TRAINED conv layers\n",
    "        print(f\"  [Step 2] Extracting CNN features...\")\n",
    "        cnn_tr = extract_features_from_cnn(model, img_tr, device)\n",
    "        cnn_val = extract_features_from_cnn(model, img_val, device)\n",
    "        print(f\"    Raw CNN features: {cnn_tr.shape[1]}\")\n",
    "        \n",
    "        # Step 3: Reduce CNN features with PCA\n",
    "        print(f\"  [Step 3] Reducing with PCA (1152 → {pca_components})...\")\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        cnn_tr_pca = pca.fit_transform(cnn_tr)\n",
    "        cnn_val_pca = pca.transform(cnn_val)\n",
    "        variance_explained = sum(pca.explained_variance_ratio_) * 100\n",
    "        print(f\"    Variance explained: {variance_explained:.1f}%\")\n",
    "        \n",
    "        # Combine with tabular\n",
    "        X_tr_np = X_tr.to_numpy(dtype=np.float32)\n",
    "        X_val_np = X_val.to_numpy(dtype=np.float32)\n",
    "        X_combined_tr = np.concatenate([cnn_tr_pca, X_tr_np], axis=1)\n",
    "        X_combined_val = np.concatenate([cnn_val_pca, X_val_np], axis=1)\n",
    "        print(f\"    Final features: {X_combined_tr.shape[1]} ({pca_components} CNN + {n_tabular} tabular)\")\n",
    "        \n",
    "        y_tr_np = y_tr.to_numpy(dtype=np.float32).reshape(-1)\n",
    "        y_val_np = y_val.to_numpy(dtype=np.float32).reshape(-1)\n",
    "        \n",
    "        # Step 4: Train Random Forest\n",
    "        print(f\"  [Step 4] Training Random Forest ({n_estimators} trees)...\")\n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_combined_tr, y_tr_np)\n",
    "        \n",
    "        preds = rf.predict(X_combined_val)\n",
    "        rmse = compute_rmse(preds, y_val_np)\n",
    "        fold_rmses.append(rmse)\n",
    "        print(f\"  [Result] Fold {fold_idx+1} RMSE: {rmse:.4f}\\n\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"FINAL: Average RMSE = {np.mean(fold_rmses):.4f} (+/- {np.std(fold_rmses):.4f})\")\n",
    "    print(\"=\"*60)\n",
    "    return fold_rmses\n",
    "\n",
    "\n",
    "# Run it\n",
    "fold_rmses_rf = run_cv_cnn_rf(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    all_images=all_images,\n",
    "    cv_splitter=rkf,\n",
    "    n_neurons=4, # keep it at 4 !\n",
    "    batch_size=32,\n",
    "    lr=0.002,\n",
    "    cnn_epochs=20, # keep it at 15 !\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    pca_components=20  # Reduce 1152 CNN features to 20, balancing with 18 tabular features\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c17ffc",
   "metadata": {},
   "source": [
    "### Ensemble: CNN + CNN-PCA-RF (50-50 blend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27714917",
   "metadata": {},
   "source": [
    "#### Why Use Different CNN Configurations for the Two Models?\n",
    "\n",
    "##### The Problem with Shared Weights\n",
    "\n",
    "Using the same CNN weights for both the neural network predictor and the Random Forest feature extractor leads to suboptimal performance. This happens for two key reasons:\n",
    "\n",
    "1. **Overfitting to the Prediction Task**: A CNN trained with 16 neurons over 35 epochs becomes highly specialized for direct prediction. Its convolutional layers learn features that are optimized for the final fully-connected layers, not for general-purpose feature extraction.\n",
    "\n",
    "2. **Lazy Feature Extraction**: When the CNN has more capacity (16 neurons), the convolutional layers can \"rely\" on the dense layers to do more of the work. This produces less informative image features.\n",
    "\n",
    "##### The Solution: Separate CNN Training\n",
    "\n",
    "For the CNN+PCA+RF pipeline, we use a smaller, less-trained CNN (4 neurons, 20 epochs):\n",
    "\n",
    "| Configuration | CNN (Direct Prediction) | CNN (Feature Extraction for RF) |\n",
    "|---------------|------------------------|--------------------------------|\n",
    "| Neurons | 16 | 4 |\n",
    "| Epochs | 35 | 20 |\n",
    "| Goal | Minimize prediction error | Extract robust image features |\n",
    "\n",
    "##### Benefits of This Approach\n",
    "\n",
    "1. **Better Feature Quality**: With only 4 neurons, the convolutional layers must work harder to compress useful information, producing richer, more discriminative features.\n",
    "\n",
    "2. **Reduced Overfitting to Noise**: Fewer training epochs prevent the CNN from memorizing noise in the training data, leading to more generalizable features.\n",
    "\n",
    "3. **Lower Error Correlation**: Since the two models are trained differently, they tend to make different mistakes. This is crucial for ensembling — the 50-50 blend only improves performance when the models' errors are uncorrelated.\n",
    "\n",
    "##### Impact on Ensemble Performance\n",
    "\n",
    "When errors are uncorrelated, averaging predictions reduces variance:\n",
    "\n",
    "$$\\text{RMSE}_{ensemble} \\approx \\text{RMSE}_{individual} \\times \\sqrt{\\frac{1 + \\rho}{2}}$$\n",
    "\n",
    "Where $\\rho$ is the correlation between model errors. Lower $\\rho$ → greater improvement from ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "506f2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENSEMBLE: CNN + CNN-PCA-RF (50-50 blend)\n",
      "============================================================\n",
      "  Folds: 10\n",
      "  Model 1 (CNN): epochs=35, n_neurons=16, lr=0.002\n",
      "  Model 2 (CNN+PCA+RF): cnn_epochs=20, n_neurons=4\n",
      "    PCA: 1152 → 20, RF: 300 trees, max_depth=10\n",
      "  Blend weights: CNN=50%, RF=50%\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Fold 1/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.008525\n",
      "      Epoch 10/35 - Loss: 0.002463\n",
      "      Epoch 20/35 - Loss: 0.001758\n",
      "      Epoch 30/35 - Loss: 0.001360\n",
      "    CNN RMSE: 0.0498\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.138054\n",
      "      Epoch 10/20 - Loss: 0.010736\n",
      "      Epoch 20/20 - Loss: 0.006908\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0402\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0365 <<<\n",
      "      (CNN: 0.0498, RF: 0.0402)\n",
      "\n",
      "============================================================\n",
      "Fold 2/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.008117\n",
      "      Epoch 10/35 - Loss: 0.002016\n",
      "      Epoch 20/35 - Loss: 0.001702\n",
      "      Epoch 30/35 - Loss: 0.001203\n",
      "    CNN RMSE: 0.0517\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.011057\n",
      "      Epoch 10/20 - Loss: 0.002897\n",
      "      Epoch 20/20 - Loss: 0.001830\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0469\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0429 <<<\n",
      "      (CNN: 0.0517, RF: 0.0469)\n",
      "\n",
      "============================================================\n",
      "Fold 3/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.004133\n",
      "      Epoch 10/35 - Loss: 0.000399\n",
      "      Epoch 20/35 - Loss: 0.000123\n",
      "      Epoch 30/35 - Loss: 0.000047\n",
      "    CNN RMSE: 0.0367\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.101996\n",
      "      Epoch 10/20 - Loss: 0.002318\n",
      "      Epoch 20/20 - Loss: 0.001458\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0383\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0330 <<<\n",
      "      (CNN: 0.0367, RF: 0.0383)\n",
      "\n",
      "============================================================\n",
      "Fold 4/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.005792\n",
      "      Epoch 10/35 - Loss: 0.001123\n",
      "      Epoch 20/35 - Loss: 0.000525\n",
      "      Epoch 30/35 - Loss: 0.000218\n",
      "    CNN RMSE: 0.0350\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.006560\n",
      "      Epoch 10/20 - Loss: 0.002251\n",
      "      Epoch 20/20 - Loss: 0.001584\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0442\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0339 <<<\n",
      "      (CNN: 0.0350, RF: 0.0442)\n",
      "\n",
      "============================================================\n",
      "Fold 5/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.008947\n",
      "      Epoch 10/35 - Loss: 0.001491\n",
      "      Epoch 20/35 - Loss: 0.000451\n",
      "      Epoch 30/35 - Loss: 0.000226\n",
      "    CNN RMSE: 0.0364\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.050980\n",
      "      Epoch 10/20 - Loss: 0.002844\n",
      "      Epoch 20/20 - Loss: 0.002294\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0457\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0371 <<<\n",
      "      (CNN: 0.0364, RF: 0.0457)\n",
      "\n",
      "============================================================\n",
      "Fold 6/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.006319\n",
      "      Epoch 10/35 - Loss: 0.001573\n",
      "      Epoch 20/35 - Loss: 0.000347\n",
      "      Epoch 30/35 - Loss: 0.000137\n",
      "    CNN RMSE: 0.0376\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.005405\n",
      "      Epoch 10/20 - Loss: 0.001027\n",
      "      Epoch 20/20 - Loss: 0.000375\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0431\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0330 <<<\n",
      "      (CNN: 0.0376, RF: 0.0431)\n",
      "\n",
      "============================================================\n",
      "Fold 7/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.014998\n",
      "      Epoch 10/35 - Loss: 0.002001\n",
      "      Epoch 20/35 - Loss: 0.000820\n",
      "      Epoch 30/35 - Loss: 0.000313\n",
      "    CNN RMSE: 0.0396\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.008624\n",
      "      Epoch 10/20 - Loss: 0.006876\n",
      "      Epoch 20/20 - Loss: 0.006883\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0409\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0340 <<<\n",
      "      (CNN: 0.0396, RF: 0.0409)\n",
      "\n",
      "============================================================\n",
      "Fold 8/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.005575\n",
      "      Epoch 10/35 - Loss: 0.001667\n",
      "      Epoch 20/35 - Loss: 0.000515\n",
      "      Epoch 30/35 - Loss: 0.000288\n",
      "    CNN RMSE: 0.0385\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.007959\n",
      "      Epoch 10/20 - Loss: 0.001023\n",
      "      Epoch 20/20 - Loss: 0.000469\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0432\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0362 <<<\n",
      "      (CNN: 0.0385, RF: 0.0432)\n",
      "\n",
      "============================================================\n",
      "Fold 9/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.008602\n",
      "      Epoch 10/35 - Loss: 0.002192\n",
      "      Epoch 20/35 - Loss: 0.000842\n",
      "      Epoch 30/35 - Loss: 0.000320\n",
      "    CNN RMSE: 0.0497\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.014427\n",
      "      Epoch 10/20 - Loss: 0.002776\n",
      "      Epoch 20/20 - Loss: 0.002447\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0481\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0430 <<<\n",
      "      (CNN: 0.0497, RF: 0.0481)\n",
      "\n",
      "============================================================\n",
      "Fold 10/10\n",
      "  Train: 800, Val: 200\n",
      "============================================================\n",
      "\n",
      "  [Model 1: CNN]\n",
      "    Training (35 epochs)...\n",
      "      Epoch 1/35 - Loss: 0.012592\n",
      "      Epoch 10/35 - Loss: 0.001489\n",
      "      Epoch 20/35 - Loss: 0.000541\n",
      "      Epoch 30/35 - Loss: 0.000259\n",
      "    CNN RMSE: 0.0384\n",
      "\n",
      "  [Model 2: CNN + PCA + RF]\n",
      "    Training CNN for feature extraction (20 epochs)...\n",
      "      Epoch 1/20 - Loss: 0.034494\n",
      "      Epoch 10/20 - Loss: 0.002824\n",
      "      Epoch 20/20 - Loss: 0.002466\n",
      "    Extracting CNN features + PCA...\n",
      "    Training Random Forest (300 trees)...\n",
      "    CNN+PCA+RF RMSE: 0.0439\n",
      "\n",
      "  >>> ENSEMBLE RMSE: 0.0363 <<<\n",
      "      (CNN: 0.0384, RF: 0.0439)\n",
      "\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "  CNN only:        0.0413 (+/- 0.0061)\n",
      "  CNN+PCA+RF only: 0.0434 (+/- 0.0029)\n",
      "  ENSEMBLE (50-50): 0.0366 (+/- 0.0035)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_cv_ensemble(X_train, y_train, all_images, cv_splitter,\n",
    "                    n_neurons_cnn=16, batch_size=32, lr=0.001, cnn_epochs=35,\n",
    "                    n_neurons_rf=4, rf_cnn_epochs=20, n_estimators=300, max_depth=10, pca_components=20,\n",
    "                    weight_cnn=0.5):\n",
    "    \"\"\"\n",
    "    Ensemble: Train both CNN and CNN+PCA+RF, blend predictions 50-50.\n",
    "    \n",
    "    weight_cnn: weight for CNN predictions (default 0.5 = equal blend)\n",
    "    \"\"\"\n",
    "    fold_rmses_cnn = []\n",
    "    fold_rmses_rf = []\n",
    "    fold_rmses_ensemble = []\n",
    "    n_folds = cv_splitter.get_n_splits()\n",
    "    n_tabular = X_train.shape[1]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ENSEMBLE: CNN + CNN-PCA-RF (50-50 blend)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Folds: {n_folds}\")\n",
    "    print(f\"  Model 1 (CNN): epochs={cnn_epochs}, n_neurons={n_neurons_cnn}, lr={lr}\")\n",
    "    print(f\"  Model 2 (CNN+PCA+RF): cnn_epochs={rf_cnn_epochs}, n_neurons={n_neurons_rf}\")\n",
    "    print(f\"    PCA: 1152 → {pca_components}, RF: {n_estimators} trees, max_depth={max_depth}\")\n",
    "    print(f\"  Blend weights: CNN={weight_cnn:.0%}, RF={1-weight_cnn:.0%}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_train)):\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Fold {fold_idx+1}/{n_folds}\")\n",
    "        print(f\"  Train: {len(train_idx)}, Val: {len(val_idx)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        img_tr = [all_images[i] for i in train_idx]\n",
    "        img_val = [all_images[i] for i in val_idx]\n",
    "        \n",
    "        y_val_np = y_val.to_numpy(dtype=np.float32).reshape(-1)\n",
    "        \n",
    "        # =============================================\n",
    "        # MODEL 1: Full CNN\n",
    "        # =============================================\n",
    "        print(f\"\\n  [Model 1: CNN]\")\n",
    "        train_ds = HeartDataset(X_tr, y_tr, preloaded_images=img_tr)\n",
    "        val_ds = HeartDataset(X_val, y_val, preloaded_images=img_val)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "        \n",
    "        model_cnn = MultiModalCNN(n_tabular_features=n_tabular, n_neurons=n_neurons_cnn).to(device)\n",
    "        optimizer = optim.Adam(model_cnn.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        print(f\"    Training ({cnn_epochs} epochs)...\")\n",
    "        model_cnn.train()\n",
    "        for epoch in range(cnn_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for imgs, tabs, labels in train_loader:\n",
    "                imgs, tabs, labels = imgs.to(device), tabs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model_cnn(imgs, tabs).squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "                print(f\"      Epoch {epoch+1}/{cnn_epochs} - Loss: {epoch_loss/len(train_loader):.6f}\")\n",
    "        \n",
    "        # Get CNN predictions\n",
    "        model_cnn.eval()\n",
    "        preds_cnn = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, tabs, _ in val_loader:\n",
    "                imgs, tabs = imgs.to(device), tabs.to(device)\n",
    "                preds_cnn.append(model_cnn(imgs, tabs).squeeze().cpu().numpy())\n",
    "        preds_cnn = np.concatenate(preds_cnn)\n",
    "        rmse_cnn = compute_rmse(preds_cnn, y_val_np)\n",
    "        fold_rmses_cnn.append(rmse_cnn)\n",
    "        print(f\"    CNN RMSE: {rmse_cnn:.4f}\")\n",
    "        \n",
    "        # =============================================\n",
    "        # MODEL 2: CNN + PCA + Random Forest\n",
    "        # =============================================\n",
    "        print(f\"\\n  [Model 2: CNN + PCA + RF]\")\n",
    "        \n",
    "        # Train a separate CNN for feature extraction\n",
    "        model_rf = MultiModalCNN(n_tabular_features=n_tabular, n_neurons=n_neurons_rf).to(device)\n",
    "        optimizer = optim.Adam(model_rf.parameters(), lr=lr)\n",
    "        \n",
    "        print(f\"    Training CNN for feature extraction ({rf_cnn_epochs} epochs)...\")\n",
    "        model_rf.train()\n",
    "        for epoch in range(rf_cnn_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for imgs, tabs, labels in train_loader:\n",
    "                imgs, tabs, labels = imgs.to(device), tabs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model_rf(imgs, tabs).squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "                print(f\"      Epoch {epoch+1}/{rf_cnn_epochs} - Loss: {epoch_loss/len(train_loader):.6f}\")\n",
    "        \n",
    "        # Extract features\n",
    "        print(f\"    Extracting CNN features + PCA...\")\n",
    "        cnn_tr = extract_features_from_cnn(model_rf, img_tr, device)\n",
    "        cnn_val = extract_features_from_cnn(model_rf, img_val, device)\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        cnn_tr_pca = pca.fit_transform(cnn_tr)\n",
    "        cnn_val_pca = pca.transform(cnn_val)\n",
    "        \n",
    "        # Combine with tabular\n",
    "        X_tr_np = X_tr.to_numpy(dtype=np.float32)\n",
    "        X_val_np = X_val.to_numpy(dtype=np.float32)\n",
    "        X_combined_tr = np.concatenate([cnn_tr_pca, X_tr_np], axis=1)\n",
    "        X_combined_val = np.concatenate([cnn_val_pca, X_val_np], axis=1)\n",
    "        y_tr_np = y_tr.to_numpy(dtype=np.float32).reshape(-1)\n",
    "        \n",
    "        # Train RF\n",
    "        print(f\"    Training Random Forest ({n_estimators} trees)...\")\n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_combined_tr, y_tr_np)\n",
    "        \n",
    "        preds_rf = rf.predict(X_combined_val)\n",
    "        rmse_rf = compute_rmse(preds_rf, y_val_np)\n",
    "        fold_rmses_rf.append(rmse_rf)\n",
    "        print(f\"    CNN+PCA+RF RMSE: {rmse_rf:.4f}\")\n",
    "        \n",
    "        # =============================================\n",
    "        # ENSEMBLE: Blend 50-50\n",
    "        # =============================================\n",
    "        preds_ensemble = weight_cnn * preds_cnn + (1 - weight_cnn) * preds_rf\n",
    "        rmse_ensemble = compute_rmse(preds_ensemble, y_val_np)\n",
    "        fold_rmses_ensemble.append(rmse_ensemble)\n",
    "        \n",
    "        print(f\"\\n  >>> ENSEMBLE RMSE: {rmse_ensemble:.4f} <<<\")\n",
    "        print(f\"      (CNN: {rmse_cnn:.4f}, RF: {rmse_rf:.4f})\\n\")\n",
    "    \n",
    "    # Final results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  CNN only:        {np.mean(fold_rmses_cnn):.4f} (+/- {np.std(fold_rmses_cnn):.4f})\")\n",
    "    print(f\"  CNN+PCA+RF only: {np.mean(fold_rmses_rf):.4f} (+/- {np.std(fold_rmses_rf):.4f})\")\n",
    "    print(f\"  ENSEMBLE (50-50): {np.mean(fold_rmses_ensemble):.4f} (+/- {np.std(fold_rmses_ensemble):.4f})\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return fold_rmses_cnn, fold_rmses_rf, fold_rmses_ensemble\n",
    "\n",
    "\n",
    "# Run ensemble\n",
    "rmses_cnn, rmses_rf, rmses_ensemble = run_cv_ensemble(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    all_images=all_images,\n",
    "    cv_splitter=rkf,\n",
    "    n_neurons_cnn=16,\n",
    "    batch_size=32,\n",
    "    lr=0.002,\n",
    "    cnn_epochs=35,\n",
    "    n_neurons_rf=4,\n",
    "    rf_cnn_epochs=20,\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    pca_components=20,\n",
    "    weight_cnn=0.5  # 50% CNN + 50% RF\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2870_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
