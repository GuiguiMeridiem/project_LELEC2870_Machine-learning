{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f6b18-1eee-40a9-940e-704145a7c672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf687fb8-4880-4f05-bc35-69b8762a562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Smurf Heart Failure Project: Part 1 (Simple Linear Regression) ---\n",
      "Loading training data (X_train.csv, y_train.csv)...\n",
      "Building preprocessing pipeline...\n",
      "Fitting preprocessor on training data...\n",
      "Training Linear Model (LinearRegression)...\n",
      "...Model training complete.\n",
      "Loading test data (X_test.csv, y_test.csv)...\n",
      "Applying fitted preprocessor to test data...\n",
      "Making predictions on training set...\n",
      "Making predictions on test set...\n",
      "\n",
      "==================================================\n",
      "     PART 1 BASELINE MODEL EVALUATION (LinearRegression)\n",
      "Training Set RMSE: 0.054224\n",
      "Test Set RMSE: 0.055820\n",
      "==================================================\n",
      "\n",
      "Saved final preprocessor to 'smurf_preprocessor.joblib'\n",
      "Saved final linear model to 'linear_model_simple.joblib'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression  # <-- CHANGED\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"--- Smurf Heart Failure Project: Part 1 (Simple Linear Regression) ---\")\n",
    "\n",
    "try:\n",
    "    # === 1. LOAD TRAINING DATA ===\n",
    "    print(\"Loading training data (X_train.csv, y_train.csv)...\")\n",
    "    df_X_train = pd.read_csv(\"data/data_labeled/X_train.csv\")\n",
    "    df_y_train = pd.read_csv(\"data/data_labeled/y_train.csv\", header=None, names=['heart_failure_risk'])\n",
    "    \n",
    "    # Flatten y_train to the (n_samples,) shape sklearn expects\n",
    "    y_train = df_y_train['heart_failure_risk'].values\n",
    "\n",
    "    # Clean column names by replacing spaces with underscores\n",
    "    df_X_train_renamed = df_X_train.rename(columns={\n",
    "        'smurfberry liquor': 'smurfberry_liquor',\n",
    "        'smurfin donuts': 'smurfin_dots'\n",
    "    })\n",
    "\n",
    "    # === 2. DEFINE PREPROCESSING PIPELINE ===\n",
    "    print(\"Building preprocessing pipeline...\")\n",
    "    \n",
    "    # Define which columns go into which transformer\n",
    "    numerical_features = [\n",
    "        'age', 'blood pressure', 'calcium', 'cholesterol', 'hemoglobin',\n",
    "        'height', 'potassium', 'vitamin D', 'weight'\n",
    "    ]\n",
    "    \n",
    "    ordinal_features = ['sarsaparilla', 'smurfberry_liquor', 'smurfin_dots']\n",
    "    \n",
    "    nominal_features = ['profession']\n",
    "    \n",
    "    # Define the specific order for the ordinal features\n",
    "    ordinal_categories = [\n",
    "        'Very low', 'Low', 'Moderate', 'High', 'Very high'\n",
    "    ]\n",
    "    # Create the list of lists for the OrdinalEncoder\n",
    "    categories_list = [ordinal_categories] * len(ordinal_features)\n",
    "\n",
    "    # Create the individual transformers\n",
    "    # No imputation needed as data was complete\n",
    "    numeric_transformer = StandardScaler()\n",
    "    ordinal_transformer = OrdinalEncoder(categories=categories_list)\n",
    "    nominal_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False) \n",
    "\n",
    "    # Build the master ColumnTransformer\n",
    "    # 'remainder='drop'' will automatically drop 'img_filename'\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('ord', ordinal_transformer, ordinal_features),\n",
    "            ('nom', nominal_transformer, nominal_features)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # === 3. FIT PREPROCESSOR AND TRAIN MODEL ===\n",
    "    print(\"Fitting preprocessor on training data...\")\n",
    "    X_train_processed = preprocessor.fit_transform(df_X_train_renamed)\n",
    "    \n",
    "    print(\"Training Linear Model (LinearRegression)...\") # <-- CHANGED\n",
    "    \n",
    "    # Use a standard LinearRegression model\n",
    "    model = LinearRegression() # <-- CHANGED\n",
    "    \n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    print(\"...Model training complete.\") # <-- REMOVED alpha print\n",
    "\n",
    "    # === 4. LOAD AND PROCESS TEST DATA ===\n",
    "    print(\"Loading test data (X_test.csv, y_test.csv)...\")\n",
    "    df_X_test = pd.read_csv(\"data/data_labeled/X_test.csv\")\n",
    "    df_y_test = pd.read_csv(\"data/data_labeled/y_test.csv\", header=None, names=['heart_failure_risk'])\n",
    "    y_true = df_y_test['heart_failure_risk'].values\n",
    "\n",
    "    # Apply the SAME column renaming to the test set\n",
    "    df_X_test_renamed = df_X_test.rename(columns={\n",
    "        'smurfberry liquor': 'smurfberry_liquor',\n",
    "        'smurfin donuts': 'smurfin_dots'\n",
    "    })\n",
    "    \n",
    "    print(\"Applying fitted preprocessor to test data...\")\n",
    "    # CRITICAL: Use .transform() only. DO NOT .fit() on test data.\n",
    "    X_test_processed = preprocessor.transform(df_X_test_renamed)\n",
    "\n",
    "    # === 5. MAKE PREDICTIONS AND EVALUATE ===\n",
    "    print(\"Making predictions on training set...\")\n",
    "    y_pred_train = model.predict(X_train_processed)\n",
    "    \n",
    "    print(\"Making predictions on test set...\")\n",
    "    y_pred_test = model.predict(X_test_processed)\n",
    "\n",
    "    # Calculate RMSE for both training and test sets\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_true, y_pred_test))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"     PART 1 BASELINE MODEL EVALUATION (LinearRegression)\") # <-- CHANGED\n",
    "    print(f\"Training Set RMSE: {rmse_train:.6f}\")\n",
    "    print(f\"Test Set RMSE: {rmse_test:.6f}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # === 6. SAVE THE FINAL PIPELINE AND MODEL ===\n",
    "    # These files are now ready for Part 2\n",
    "    joblib.dump(preprocessor, 'smurf_preprocessor.joblib')\n",
    "    joblib.dump(model, 'linear_model_simple.joblib') # <-- CHANGED\n",
    "    print(\"Saved final preprocessor to 'smurf_preprocessor.joblib'\")\n",
    "    print(\"Saved final linear model to 'linear_model_simple.joblib'\") # <-- CHANGED\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR: File not found.\")\n",
    "    print(f\"Please make sure X_train.csv, y_train.csv, X_test.csv, and y_test.csv are in the same directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")\n",
    "    print(\"This might be due to unexpected values in the CSV files (e.g., a new 'profession' or a different ordinal value).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06e06f-dd32-47ec-811a-528c22fd4f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
